{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D,GlobalAveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(r'C:\\Users\\Dell.com\\Desktop\\images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(r'C:\\Users\\Dell.com\\Desktop\\meta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head \"C:\\Users\\Dell.com\\Desktop\\meta\\train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head \"C:\\Users\\Dell.com\\Desktop\\meta\\classes.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data, showing one image per class from 101 classes\n",
    "rows = 17\n",
    "cols = 6\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(25,25))\n",
    "fig.suptitle(\"Showing one random image from each class\", y=1.05, fontsize=24)\n",
    "data_dir = r\"C:\\Users\\Dell.com\\Desktop\\images\"\n",
    "foods_sorted = sorted(os.listdir(data_dir))\n",
    "food_id = 0\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        try:\n",
    "            food_selected = foods_sorted[food_id]\n",
    "            food_id += 1\n",
    "        except:\n",
    "            break\n",
    "    if food_selected == '.DS_Store':\n",
    "        continue\n",
    "    food_selected_images = os.listdir(os.path.join(data_dir,food_selected)) \n",
    "    food_selected_random = np.random.choice(food_selected_images)   \n",
    "    img = plt.imread(os.path.join(data_dir,food_selected, food_selected_random))\n",
    "    ax[i][j].imshow(img)\n",
    "    ax[i][j].set_title(food_selected, pad = 10)\n",
    "    plt.setp(ax, xticks=[],yticks=[])\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Helper method to split dataset into train and test folders\n",
    "def prepare_data(filepath, src,dest):\n",
    "    classes_images = defaultdict(list)\n",
    "    with open(filepath, 'r') as txt:\n",
    "        paths = [read.strip() for read in txt.readlines()]\n",
    "        for p in paths:\n",
    "            food = p.split('/')\n",
    "            classes_images[food[0]].append(food[1] + '.jpg')\n",
    "    for food in classes_images.keys():\n",
    "        print(\"\\nCopying images into \",food)\n",
    "    if not os.path.exists(os.path.join(dest,food)):\n",
    "        os.makedirs(os.path.join(dest,food))\n",
    "    for i in classes_images[food]:\n",
    "        copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating train data...\")\n",
    "prepare_data(r\"C:\\Users\\Dell.com\\Desktop\\meta\\train.txt\",r\"C:\\Users\\Dell.com\\Desktop\\images\",'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating test data...\")\n",
    "prepare_data(r'C:\\Users\\Dell.com\\Desktop\\meta\\test.txt',r\"C:\\Users\\Dell.com\\Desktop\\images\",'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Check how many files are in the train folder\n",
    "print(\"Total number of samples in train folder\")\n",
    "!find train -type d -or -type f -printf '.' | wc -c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many files are in the test folder\n",
    "print(\"Total number of samples in test folder\")\n",
    "!find test -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del foods_sorted[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_mini(food_list, src, dest):\n",
    "    if os.path.exists(dest):\n",
    "        rmtree(dest) \n",
    "    os.makedirs(dest)\n",
    "    for food_item in food_list :\n",
    "        print(\"Copying images into\",food_item)\n",
    "    copytree(os.path.join(src,food_item), os.path.join(dest,food_item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # picking 3 food items and generating separate data folders for the same\n",
    "food_list = ['apple_pie','pizza','omelette']\n",
    "src_train = r'C:\\Users\\Dell.com\\Desktop\\meta\\train.txt'\n",
    "dest_train = r'C:\\Users\\Dell.com\\Desktop\\ml\\project 9\\train'\n",
    "src_test = r\"C:\\Users\\Dell.com\\Desktop\\meta\\test.txt\"\n",
    "dest_test = r\"C:\\Users\\Dell.com\\Desktop\\ml\\project 9\\test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating train data folder with new classes\")\n",
    "dataset_mini(food_list, src_train, dest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in train folder\")\n",
    "!find /kaggle/working/train_mini -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating test data folder with new classes\")\n",
    "dataset_mini(food_list, src_test, dest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in test folder\")\n",
    "!find /kaggle/working/test_mini -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "K.clear_session()\n",
    "n_classes = 3\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = 'train_mini'\n",
    "validation_data_dir = 'test_mini'\n",
    "nb_train_samples = 2250 #75750\n",
    "nb_validation_samples = 750 #25250\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "resnet50 = ResNet50(weights='imagenet', include_top=False)\n",
    "x = resnet50.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(3,kernel_regularizer=regularizers.l2(0.005),activation='softmax')(x)\n",
    "model = Model(inputs=resnet50.input, outputs=predictions)\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='best_model_3class.hdf5', verbose=1,save_best_only=True)\n",
    "csv_logger = CSVLogger('history_3class.log')\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                steps_per_epoch = nb_train_samples // batch_size,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=nb_validation_samples // batch_size,\n",
    "                epochs=30,\n",
    "                verbose=1,\n",
    "                callbacks=[csv_logger, checkpointer])\n",
    "model.save('model_trained_3class.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map_3 = train_generator.class_indices\n",
    "class_map_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "    plt.show()\n",
    "def plot_loss(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(history,'FOOD101-ResNet50')\n",
    "plot_loss(history,'FOOD101-ResNet50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loading the best saved model to make predictions\n",
    "K.clear_session()\n",
    "model_best = load_model('/kaggle/working/best_model_3class.hdf5',compile =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, images, show = True):\n",
    "    for img in images:\n",
    "        img = image.load_img(img, target_size=(224, 224))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img /= 255.\n",
    "    pred = model.predict(img)\n",
    "    index = np.argmax(pred)\n",
    "    food_list.sort()\n",
    "    pred_value = food_list[index]\n",
    "    if show:\n",
    "        plt.imshow(img[0])\n",
    "        plt.axis('off')\n",
    "        plt.title(pred_value)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "images.append('applepie.jpg')\n",
    "images.append('pizza.jpg')\n",
    "images.append('omelette.jpg')\n",
    "predict_class(model_best, images, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_n_random_classes(n):\n",
    "    food_list = []\n",
    "    random_food_indices = random.sample(range(len(foods_sorted)),n)\n",
    "    for i in random_food_indices:\n",
    "        food_list.append(foods_sorted[i])\n",
    "    food_list.sort()\n",
    "    return food_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 11\n",
    "food_list = pick_n_random_classes(n)\n",
    "food_list = ['apple_pie', 'beef_carpaccio', 'bibimbap', 'cup_cakes',\n",
    "'foie_gras', 'french_fries', 'garlic_bread', 'pizza', 'spring_rolls','spaghetti_carbonara', 'strawberry_shortcake']\n",
    "print(\"These are the randomly picked food classes we will be training the model on...\\n\", food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating training data folder with new classes...\")\n",
    "dataset_mini(food_list, src_train, dest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in train folder\")\n",
    "!find train_mini/ -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating test data folder with new classes\")\n",
    "dataset_mini(food_list, src_test, dest_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in test folder\")\n",
    "!find test_mini/ -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "n_classes = n\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = 'train_mini'\n",
    "validation_data_dir = 'test_mini'\n",
    "nb_train_samples = 8250 #75750\n",
    "nb_validation_samples = 2750 #25250\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "resnet50 = ResNet50(weights='imagenet', include_top=False)\n",
    "x = resnet50.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "predictions = Dense(n,kernel_regularizer=regularizers.l2(0.005),activation='softmax')(x)\n",
    "model = Model(inputs=resnet50.input, outputs=predictions)\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='best_model_11class.hdf5', verbose=1,save_best_only=True)\n",
    "csv_logger = CSVLogger('history_11class.log')\n",
    "\n",
    "history_11class = model.fit_generator(train_generator,\n",
    "                steps_per_epoch = nb_train_samples // batch_size,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=nb_validation_samples // batch_size,\n",
    "                epochs=30,\n",
    "                verbose=1,\n",
    "                callbacks=[csv_logger, checkpointer])\n",
    "\n",
    "model.save('model_trained_11class.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map_11 = train_generator.class_indices\n",
    "class_map_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(history_11class,'FOOD101-ResNet50')\n",
    "plot_loss(history_11class,'FOOD101-ResNet50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model_best = load_model('/kaggle/working/best_model_11class.hdf5',compile =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Make a list of downloaded images and test the trained model\n",
    "images = []\n",
    "images.append('cupcakes.jpg')\n",
    "# images.append('pizza.jpg')\n",
    "images.append('springrolls.jpg')\n",
    "images.append('garlicbread.jpg')\n",
    "predict_class(model_best, images, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"AbdulQadeer/Dataset/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True,show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
